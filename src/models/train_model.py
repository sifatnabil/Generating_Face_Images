import os

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import wandb
from dotenv import load_dotenv
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from torchmetrics.image.fid import FrechetInceptionDistance

from src.models.discriminator_model import Discriminator
from src.models.generator_model import Generator
from src.models.hyperparameters import *

# Load the ENV file containing the API Key for WandB
load_dotenv()

def initialize_weights(model):
    # Initializes weights according to the DCGAN paper
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):
            nn.init.normal_(m.weight.data, 0.0, 0.02)

def load_dataset(path):
    transforms = transforms.Compose(
        [
            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(
                [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]
            ),
        ]
    )

    dataset = datasets.ImageFolder(root=path, transform=transforms)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
    return dataloader

def initialize_models(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN, FEATURES_DISC, device):
    gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)
    disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)

    return gen, disc

def train():
    ROOT_DIR = os.path.abspath(os.curdir)
    DATASET_PATH = os.path.join(ROOT_DIR, 'data', 'processed')
    dataloader = load_dataset(DATASET_PATH)

    gen, disc = initialize_weights(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN, FEATURES_DISC, device)
    
    initialize_weights(gen)
    initialize_weights(disc)

    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(BETA_1, 0.999))
    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(BETA_1, 0.999))

    criterion = nn.BCELoss()

    fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)

    wandb.watch(gen, log_freq=100)
    wandb.watch(disc, log_freq=100)

    fid = FrechetInceptionDistance(feature=FEATURES_GEN)

    gen.train()
    disc.train()

    for epoch in range(NUM_EPOCHS):
    
        for batch_idx, (real, _) in enumerate(dataloader):
            real = real.to(device)
            noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)
            fake = gen(noise)

            # Train Discriminator
            disc_real = disc(real).reshape(-1)
            loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))
            disc_fake = disc(fake.detach()).reshape(-1)
            loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))
            loss_disc = (loss_disc_real + loss_disc_fake) / 2
            disc.zero_grad()
            loss_disc.backward()
            opt_disc.step()

            # Train Generator
            output = disc(fake).reshape(-1)
            loss_gen = criterion(output, torch.ones_like(output))
            gen.zero_grad()
            loss_gen.backward()
            opt_gen.step()

            if batch_idx % 100 == 0:
                print(
                    f"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \
                    Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}"
                )

                wandb.log({"Generator Loss": loss_gen})
                wandb.log({"Discriminator Loss": loss_disc})

                with torch.no_grad():
                    fake = gen(fixed_noise)
                    # take out (up to) 32 examples
                    img_grid_real = torchvision.utils.make_grid(
                        real[:32], normalize=True
                    )
                    img_grid_fake = torchvision.utils.make_grid(
                        fake[:32], normalize=True
                    )

                    real_images = wandb.Image(img_grid_real, caption="Real")
                    wandb.log({"Actual Training Images": real_images})

                    fake_images = wandb.Image(img_grid_fake, caption="Fake")
                    wandb.log({"Images Generated by the model": fake_images})

                    if batch_idx % (len(dataloader) - 1) == 0:
                        fid.update(real[:32].cpu().type(torch.uint8), real=True)
                        fid.update(fake.cpu().type(torch.uint8), real=False)
                        current_fid = fid.compute()
                        print(f'FID Score after epoch: {epoch} is: {current_fid}')
                    
                        wandb.log({"Frechet Inception Distance Score:": current_fid})
    
                step += 1

        torch.save(gen.state_dict(), os.path.join(ROOT_DIR, 'models', 'generator.pth'))
        torch.save(disc.state_dict(), os.path.join(ROOT_DIR, 'models', 'discriminator.pth'))